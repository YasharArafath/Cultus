{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9ktrnpSi3SA"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# INSTALL DEPENDENCIES\n",
        "# ================================================================\n",
        "!pip install prophet\n",
        "!pip install lightgbm\n",
        "!pip install pmdarima\n",
        "!pip install matplotlib pandas numpy scikit-learn statsmodels tqdm\n",
        "\n",
        "# ================================================================\n",
        "# IMPORTS\n",
        "# ================================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from prophet import Prophet\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ================================================================\n",
        "# TASK 1: SIMULATED HOURLY DATA (3+ YEARS)\n",
        "# ================================================================\n",
        "np.random.seed(42)\n",
        "date_range = pd.date_range(start=\"2020-01-01\", end=\"2023-12-31 23:00\", freq=\"H\")\n",
        "n = len(date_range)\n",
        "\n",
        "# Trend\n",
        "trend = 0.0005 * np.arange(n)\n",
        "\n",
        "# Daily seasonality\n",
        "daily = 10 * np.sin(2 * np.pi * (np.arange(n) % 24) / 24)\n",
        "\n",
        "# Weekly seasonality\n",
        "weekly = 7 * np.sin(2 * np.pi * (np.arange(n) % (24*7)) / (24*7))\n",
        "\n",
        "# Noise\n",
        "noise = np.random.normal(0, 2, n)\n",
        "\n",
        "# Outliers\n",
        "outliers = np.zeros(n)\n",
        "outlier_idx = np.random.choice(n, size=int(n * 0.003), replace=False)\n",
        "outliers[outlier_idx] = np.random.normal(30, 10, len(outlier_idx))\n",
        "\n",
        "# Final series\n",
        "y = 50 + trend + daily + weekly + noise + outliers\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"ds\": date_range,\n",
        "    \"y\": y\n",
        "})\n",
        "\n",
        "df.head()\n",
        "\n",
        "# ================================================================\n",
        "# TRAIN TEST SPLIT (Last 30 days = test)\n",
        "# ================================================================\n",
        "train = df.iloc[:-24*30]\n",
        "test = df.iloc[-24*30:]\n",
        "\n",
        "# ================================================================\n",
        "# TASK 4: EXPANDING WINDOW TIME-SERIES CROSS VALIDATION\n",
        "# ================================================================\n",
        "def expanding_window_cv(data, n_folds=5, horizon=24):\n",
        "    \"\"\"\n",
        "    Expanding window cross-validation.\n",
        "    Each fold predicts 'horizon' hours ahead.\n",
        "    \"\"\"\n",
        "    fold_size = len(data) // (n_folds + 1)\n",
        "    metrics = []\n",
        "\n",
        "    print(\"Running Expanding Window CV...\")\n",
        "\n",
        "    for i in tqdm(range(n_folds)):\n",
        "        end_train = fold_size * (i + 1)\n",
        "        cv_train = data.iloc[:end_train]\n",
        "        cv_test = data.iloc[end_train:end_train + horizon]\n",
        "\n",
        "        # ----------------------\n",
        "        # Prophet\n",
        "        # ----------------------\n",
        "        p = Prophet(daily_seasonality=True, weekly_seasonality=True)\n",
        "        p.fit(cv_train)\n",
        "        future = p.make_future_dataframe(periods=horizon, freq=\"H\")\n",
        "        p_pred = p.predict(future).iloc[-horizon:][\"yhat\"].values\n",
        "\n",
        "        # ----------------------\n",
        "        # SARIMAX\n",
        "        # ----------------------\n",
        "        sarimax = SARIMAX(cv_train.y, order=(1,1,1), seasonal_order=(1,1,1,24))\n",
        "        sarimax_fit = sarimax.fit(disp=False)\n",
        "        s_pred = sarimax_fit.forecast(steps=horizon)\n",
        "\n",
        "        # ----------------------\n",
        "        # LightGBM\n",
        "        # ----------------------\n",
        "        lgb_train = cv_train.copy()\n",
        "        lgb_train[\"hour\"] = lgb_train[\"ds\"].dt.hour\n",
        "        lgb_train[\"dayofweek\"] = lgb_train[\"ds\"].dt.dayofweek\n",
        "\n",
        "        lgb_test = cv_test.copy()\n",
        "        lgb_test[\"hour\"] = lgb_test[\"ds\"].dt.hour\n",
        "        lgb_test[\"dayofweek\"] = lgb_test[\"ds\"].dt.dayofweek\n",
        "\n",
        "        model_lgb = LGBMRegressor()\n",
        "        model_lgb.fit(lgb_train[[\"hour\",\"dayofweek\"]], lgb_train[\"y\"])\n",
        "        l_pred = model_lgb.predict(lgb_test[[\"hour\",\"dayofweek\"]])\n",
        "\n",
        "        # ----------------------\n",
        "        # METRICS\n",
        "        # ----------------------\n",
        "        actual = cv_test.y.values\n",
        "        blended = (p_pred + s_pred + l_pred) / 3  # simple blend per fold\n",
        "\n",
        "        mae = mean_absolute_error(actual, blended)\n",
        "        rmse = np.sqrt(mean_squared_error(actual, blended))\n",
        "        wape = np.sum(np.abs(actual - blended)) / np.sum(np.abs(actual))\n",
        "\n",
        "        metrics.append([mae, rmse, wape])\n",
        "\n",
        "    return pd.DataFrame(metrics, columns=[\"MAE\", \"RMSE\", \"WAPE\"])\n",
        "\n",
        "cv_results = expanding_window_cv(train)\n",
        "print(\"\\nCross Validation Results:\")\n",
        "cv_results, cv_results.mean()\n",
        "\n",
        "# ================================================================\n",
        "# TASK 2 & 3: TRAIN FINAL MODELS + STACKING ENSEMBLE\n",
        "# ================================================================\n",
        "# -------- Prophet --------\n",
        "prophet = Prophet(daily_seasonality=True, weekly_seasonality=True)\n",
        "prophet.fit(train)\n",
        "future = prophet.make_future_dataframe(periods=24*30, freq=\"H\")\n",
        "p_forecast = prophet.predict(future).iloc[-24*30:][\"yhat\"].values\n",
        "\n",
        "# -------- SARIMAX --------\n",
        "sarimax_model = SARIMAX(train.y, order=(1,1,1), seasonal_order=(1,1,1,24))\n",
        "sarimax_fit = sarimax_model.fit(disp=False)\n",
        "s_forecast = sarimax_fit.forecast(steps=24*30)\n",
        "\n",
        "# -------- LightGBM --------\n",
        "train_lgb = train.copy()\n",
        "train_lgb[\"hour\"] = train_lgb[\"ds\"].dt.hour\n",
        "train_lgb[\"dow\"] = train_lgb[\"ds\"].dt.dayofweek\n",
        "\n",
        "test_lgb = test.copy()\n",
        "test_lgb[\"hour\"] = test_lgb[\"ds\"].dt.hour\n",
        "test_lgb[\"dow\"] = test_lgb[\"ds\"].dt.dayofweek\n",
        "\n",
        "lgb = LGBMRegressor()\n",
        "lgb.fit(train_lgb[[\"hour\",\"dow\"]], train_lgb[\"y\"])\n",
        "l_forecast = lgb.predict(test_lgb[[\"hour\",\"dow\"]])\n",
        "\n",
        "# -------- STACKING --------\n",
        "stack_X_train = np.vstack([\n",
        "    prophet.predict(train)[ \"yhat\" ].values,\n",
        "    sarimax_fit.fittedvalues.values,\n",
        "    lgb.predict(train_lgb[[\"hour\",\"dow\"]])\n",
        "]).T\n",
        "\n",
        "stack_y_train = train[\"y\"].values\n",
        "\n",
        "meta = Ridge()\n",
        "meta.fit(stack_X_train, stack_y_train)\n",
        "\n",
        "stack_X_test = np.vstack([p_forecast, s_forecast, l_forecast]).T\n",
        "stack_pred = meta.predict(stack_X_test)\n",
        "\n",
        "# ================================================================\n",
        "# TASK 5: PREDICTION INTERVALS (BOOTSTRAP)\n",
        "# ================================================================\n",
        "boot_preds = []\n",
        "for _ in range(50):\n",
        "    noise = np.random.normal(0, 3, len(stack_pred))\n",
        "    boot_preds.append(stack_pred + noise)\n",
        "\n",
        "boot_preds = np.array(boot_preds)\n",
        "lower = np.percentile(boot_preds, 5, axis=0)\n",
        "upper = np.percentile(boot_preds, 95, axis=0)\n",
        "\n",
        "# ================================================================\n",
        "# FINAL OUTPUT TABLE\n",
        "# ================================================================\n",
        "final_output = pd.DataFrame({\n",
        "    \"ds\": test[\"ds\"].values,\n",
        "    \"Forecast\": stack_pred,\n",
        "    \"Lower_90\": lower,\n",
        "    \"Upper_90\": upper\n",
        "})\n",
        "\n",
        "print(final_output.head())\n",
        "\n",
        "# ================================================================\n",
        "# PLOT FINAL FORECAST\n",
        "# ================================================================\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(test[\"ds\"], test[\"y\"], label=\"Actual\")\n",
        "plt.plot(test[\"ds\"], stack_pred, label=\"Forecast\")\n",
        "plt.fill_between(test[\"ds\"], lower, upper, alpha=0.2)\n",
        "plt.legend()\n",
        "plt.title(\"Final 30-Day Forecast with 90% Prediction Intervals\")\n",
        "plt.show()\n"
      ]
    }
  ]
}